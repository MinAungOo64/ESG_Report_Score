{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fef01e-ca61-4c0e-999a-24a8a4bc9783",
   "metadata": {},
   "source": [
    "## Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5c6597-c67b-4cd9-90cb-b32f9d1c4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerModel\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class LongformerForRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load the pretrained Longformer model (handles up to 4096 tokens)\n",
    "        self.longformer = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "        \n",
    "        # Dropout for regularization (prevents overfitting)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Final regression layer to predict 4 scores: e_score, s_score, g_score, total_score\n",
    "        self.regressor = nn.Linear(self.longformer.config.hidden_size, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Forward pass through Longformer\n",
    "        outputs = self.longformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Try to use pooled output (if available)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        # If pooled output is None (some models don't provide it), use mean pooling over all tokens\n",
    "        if pooled_output is None:\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)  # shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # Apply dropout\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # Pass through regression head to get 4 continuous outputs\n",
    "        return self.regressor(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fc44c56-5038-4c4a-b914-195ddce415ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LongformerForRegression()\n",
    "output_dir = \"C:/Users/steve/HuggingFace Models/LongFormer_ESG_Score\"\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load(f\"{output_dir}/pytorch_model.bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fcf23-e819-4b5e-9d8e-fdf5179f0d28",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ba0e8f-2d49-4990-9fa2-dd232f2d238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0026ce-25d7-49de-9534-5b8e2b823293",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ab1c56-f689-4970-8823-bc053ceaf968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "tokenized_dataset= load_from_disk(\"esg_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113074a2-7a40-403c-af3d-969299fbd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127507bd-e9fe-4515-877a-4fe2c5b8b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# For dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Prepare validation data in batch size of 2\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_dataset[\"test\"], batch_size=2, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767b828-fc0d-4164-84e1-1c11d46b21ba",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71ef9a0-7622-4f90-8555-76a0c687b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 27.5613\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "loss_fn = nn.MSELoss()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        inputs = {\n",
    "            \"input_ids\": batch[\"input_ids\"],\n",
    "            \"attention_mask\": batch[\"attention_mask\"]\n",
    "        }\n",
    "        labels = torch.stack([\n",
    "            batch['e_score'],\n",
    "            batch['s_score'],\n",
    "            batch['g_score'],\n",
    "            batch['total_score']\n",
    "        ], dim=1).float()\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_dataloader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
